{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sklearn as sklearn\n",
        "import seaborn as sb\n",
        "from PIL import Image\n",
        "from matplotlib import image\n",
        "from matplotlib import pyplot\n",
        "import glob\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "\n"
      ],
      "metadata": {
        "id": "oPknu9lAH8bd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Images from ORL dataset\n"
      ],
      "metadata": {
        "id": "TMEtGS5PKBJg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_all_images(path):\n",
        "    image_list = []\n",
        "    for x in range(1,41): #loop on every subject folder\n",
        "        for filename in glob.glob(path + 's' + str(x) + '/*.pgm'): #get all images inside sX folder\n",
        "            Im = Image.open(filename)\n",
        "            image_list.append(Im)\n",
        "    return image_list"
      ],
      "metadata": {
        "id": "8vWYDi87KICh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jz-0KEz89py2"
      },
      "source": [
        "# Data Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_data_matrix(path):\n",
        "  images = get_all_images(path)\n",
        "  print(len(images)) #400\n",
        "\n",
        "  #convert images list to a numpy array list\n",
        "  images_vector = []\n",
        "  for img in images:\n",
        "      images_vector.append(np.array(img).ravel())\n",
        "\n",
        "  print(len(images_vector)) #400\n",
        "  print(images_vector[0].size) #10304\n",
        "  print(images_vector[0].shape) #10304\n",
        "\n",
        "  #df = pd.DataFrame(images_vector)\n",
        "  y_labels = []\n",
        "  for i in range(1,41):\n",
        "      for j in range(1,11):\n",
        "          y_labels.append(i)\n",
        "  #df['label'] = pd.Series(y_labels)\n",
        "  labels = np.asarray(y_labels , dtype = \"int32\")\n",
        "  images_data = np.asarray(images_vector , dtype = \"int32\")\n",
        "  return images_data , labels\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "Izs4ZzfRGZo-",
        "outputId": "4af8cb9f-79f3-4a2e-c15e-7b62556c9af9"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "0\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-ab887ffb7e73>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages_vector\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#400\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages_vector\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#10304\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages_vector\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#10304\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The ORL dataset PATH\n"
      ],
      "metadata": {
        "id": "LMH1NjuZIdAq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "images_data , images_label = generate_data_matrix('/Users/batsh/Desktop/ORL dataset/')"
      ],
      "metadata": {
        "id": "MI2C27Y-Ibij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Split the data for training and test sets\n"
      ],
      "metadata": {
        "id": "S0bIHA0MIw3P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# testset\n",
        "data_matrix_Test = []\n",
        "label_matrix_Test = []\n",
        "\n",
        "#trainigset\n",
        "data_matrix_Train = []\n",
        "label_matrix_Train = []\n",
        "\n",
        "for i,index in zip(range(400) , range(400)):\n",
        "  if(i % 2 == 0):\n",
        "    data_matrix_Test.append(images_data[index])\n",
        "    label_matrix_Test.append(images_label[index])\n",
        "  else:\n",
        "    data_matrix_Train.append(images_data[index])\n",
        "    label_matrix_Train.append(images_label)\n",
        "\n",
        "\n",
        "# the trainig_dataset and test_dataset\n",
        "Data_matix_test = np.asarray(data_matrix_Test , dtype = \"int32\")\n",
        "label_matix_test = np.asarray(label_matrix_Test , dtype = \"int32\")\n",
        "\n",
        "Data_matix_train = np.asarray(data_matrix_Train , dtype = \"int32\")\n",
        "label_matix_train = np.asarray(label_matrix_Train , dtype = \"int32\")"
      ],
      "metadata": {
        "id": "WnD0r-u0I_0I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PCA"
      ],
      "metadata": {
        "id": "YkRKWyG_QigM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bwYQC3oPGijJ"
      },
      "outputs": [],
      "source": [
        "##Implementaion of Princible component analysis\n",
        "alpha = np.array(\n",
        "    [0.8,0.85,0.9,0.95]\n",
        "    )\n",
        "\n",
        "def PCA():\n",
        "  test_matrix_mean = np.mean(Data_matix_test , axis = 0)                                                    #compute mean of each dim. in the data matrix \n",
        "  train_matrix_mean = np.mean(Data_matix_train , axis = 0)\n",
        "\n",
        "  test_Z =  Data_matix_test - test_matrix_mean\n",
        "  train_Z = Data_matix_train - train_matrix_mean\n",
        "                                                                     # center data step\n",
        "  cov_train_matrix = np.cov(train_Z , rowvar = False)                                         # covariance matrix of centered data matrix Z\n",
        "  eign_values , eign_vectors = np.linalg.eigh(cov_train_matrix)                         # compute the eign_val and eign_vectors of cov_matrix\n",
        "\n",
        "  sorted_index = np.argsort(eign_values)[::-1]\n",
        "  sorted_eign_values = eign_values[sorted_index]\n",
        "  sorted_eign_vectors = eign_vectors[:sorted_index]\n",
        "\n",
        "  sum_eign_values_d = np.linalg.det(sorted_eign_values)                           #compute the sum of eign_values in d dim.\n",
        "  \n",
        "  reduced_dimention = 10304\n",
        "  #for each alpha value\n",
        "  for i in alpha:\n",
        "    \n",
        "    for itr in range(1 , 10304):\n",
        "\n",
        "      eign_values_r = sorted_eign_values[:,0:itr]                                   #subset of eign_values matrix to get the number of new dims.\n",
        "      sum_eign_values_r = np.linalg.det(eign_values_r)                              #compute the sum of eign_Values in r dim matrix (subset)\n",
        "      f_r = sum_eign_values_r / sum_eign_values_d                                   #f(r) = sum(r) / sum(d)\n",
        "                                                                                    #check if the ratio is one of given alpha in pdf\n",
        "    \n",
        "      if(f_r >= i):\n",
        "        reduced_dimention = itr                                                     #if any one is ture break\n",
        "        break\n",
        "  \n",
        "    projection_matrix = sorted_eign_vectors[:,0:reduced_dimention]\n",
        "\n",
        "    reduced_data_train_matrix = np.dot(projection_matrix.transpose() , train_Z.transpose()).transpose()\n",
        "    reduced_data_test_matrix = np.dot(projection_matrix.transpose() , test_Z.transpose())\n",
        "\n",
        "    accuracy_matrix = [] \n",
        "    #first neighbor\n",
        "    KNN = KNeighborsClassifier(n_neighbors = 1)\n",
        "    KNN.fit(reduced_data_train_matrix , label_matix_train)\n",
        "    result = KNN.predict(reduced_data_test_matrix)\n",
        "    accuracy_matrix.append(accuracy_score(result , label_matrix_Test))\n",
        "    print(\"For First Neighbor\")\n",
        "    for k in range(len(accuracy_matrix)):\n",
        "      print(\"Accuracy for alpha = \" + str(i) + \": \" + str(accuracy_matrix[k]))\n",
        "    \n",
        "    plt.plot(accuracy_matrix , alpha)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "model.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "4eb24f9b113f9fa6dbe43bfdf40db8d0bb01cfe1cd58b52defcf46a1a57fa4cd"
    },
    "kernelspec": {
      "display_name": "Python 3.8.3 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}